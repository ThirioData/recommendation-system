{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File user_features.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-db1242c3f7d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0muser_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user_features.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/demonicode/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/demonicode/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/demonicode/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/demonicode/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/demonicode/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File user_features.csv does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "import ast\n",
    "import itertools\n",
    "user_feat = pd.read_csv('user_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File user_features.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-0cac29168018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#reading data from csv files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muser_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user_features.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/demonicode/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/demonicode/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/demonicode/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/demonicode/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/demonicode/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File user_features.csv does not exist"
     ]
    }
   ],
   "source": [
    "#reading data from csv files\n",
    "\n",
    "\n",
    "\n",
    "num = np.arange(500,5000)\n",
    "num = num[0:len(user_feat)]\n",
    "user_feat['user_guid'] = num\n",
    "user_feat['Calorie'] = np.random.randint(40,500, size=len(user_feat))\n",
    "#print user_feat\n",
    "\n",
    "spice_feat = pd.read_csv('spice_features.csv')\n",
    "\n",
    "#print spice_feat\n",
    "#food user rating table\n",
    "food_user = pd.DataFrame(np.random.randint(low=0, high=2, size=(len(spice_feat),len(user_feat))),columns=user_feat.user_guid)\n",
    "food_user.index  =  spice_feat['food_id']\n",
    "#print food_user.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Normalisation\n",
    "\n",
    "def nor_age(age):\n",
    "    \n",
    "    if(age<=10):\n",
    "        return 1\n",
    "    elif(age>10 and age <=18):\n",
    "        return 2\n",
    "    elif(age>18 and age <=25):\n",
    "        return 3\n",
    "    elif(age>25 and age <=35):\n",
    "        return 4\n",
    "    elif(age>35 and age <=40):\n",
    "        return 5\n",
    "    elif(age>40 and age <=50):\n",
    "        return 6\n",
    "    elif(age>50 and age<=60):\n",
    "        return 7\n",
    "    else:\n",
    "        return 8\n",
    "    \n",
    "    \n",
    "\n",
    "s_dict = {\"M\":1,\"F\":5 }\n",
    "l_dict = {'J&K':2, 'Haryana':5, 'Punjab':6, 'U.P.':8, 'Maharashtra':10, 'South India':15}\n",
    "user_feat['Age'] = user_feat['Age'].apply(nor_age)\n",
    "user_feat  = user_feat.replace({\"Sex\":s_dict})\n",
    "user_feat  = user_feat.replace({\"Location\":l_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset for content based recommender\n",
    "spice = np.array(spice_feat.iloc[:,0:4])\n",
    "#print spice\n",
    "user_rating = pd.DataFrame(np.random.randint(low=-1, high=2, size=(len(spice_feat),len(user_feat))),columns=user_feat.user_guid)\n",
    "user_rating.index = spice_feat['food_id']\n",
    "#user tells rating and spice tells if ingrediant is there or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prepare dataset for 5 day window recommendation\n",
    "import random\n",
    "from random import randint\n",
    "\n",
    "\n",
    "recommend_data = []\n",
    "bought_data = []\n",
    "\n",
    "for i in range(100):\n",
    "    length = 3\n",
    "    my_randoms = []\n",
    "    for i in range(5):\n",
    "        my_randoms.append(random.sample(xrange(6000,7000), 3))\n",
    "    recommend_data.append(my_randoms)\n",
    "    \n",
    "    \n",
    "\n",
    "for i in range(100):\n",
    "    length = randint(0,5)\n",
    "    my_randoms = []\n",
    "    for i in range(5):\n",
    "        my_randoms.append(random.sample(xrange(6000,7000), length))\n",
    "    bought_data.append(my_randoms)\n",
    "    \n",
    "recommends = []\n",
    "for i in range(100):\n",
    "    recommends.append(random.sample(xrange(6000,7000), 3))\n",
    "\n",
    "bought = []\n",
    "for i in range(100):\n",
    "    length = randint(0,5)\n",
    "    bought.append(random.sample(xrange(6000,7000), length))\n",
    "    \n",
    "\n",
    "new_user_feat = pd.DataFrame(user_feat.user_guid)\n",
    "new_user_feat['last_5_days_recommend'] = recommend_data\n",
    "new_user_feat['last_5_days_bought'] = bought_data\n",
    "new_user_feat['recommends'] = recommends\n",
    "new_user_feat['bought']  = bought\n",
    "new_user_feat.to_csv('new_user_feat.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clustering_based(user_feat):    \n",
    "    kmeans = KMeans(n_clusters = 10,random_state=0).fit(user_feat)\n",
    "    user_feat['label'] = kmeans.labels_\n",
    "    #print user_label\n",
    "    user_feat = user_feat.sort_values(['label','Location'],ascending=[1,0])\n",
    "    user = user_feat.drop_duplicates(subset=['Location','label'])\n",
    "    user = user.groupby('label')['Location'].nlargest(3)\n",
    "    return user,user_feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_food_loc(user_group,user_id,non_recom_list,user_feat,spice_feat):\n",
    "    index = np.where(user_feat['user_guid']==user_id)[0][0]\n",
    "    print index\n",
    "    #print user_feat['label']\n",
    "    user_label = user_feat.loc[index,'label']\n",
    "    loc = user_group[user_label].tolist()\n",
    "    newspice_feat = spice_feat.set_index('food_id')\n",
    "    spice = newspice_feat[newspice_feat['Location'].isin(loc)]\n",
    "    #print spice\n",
    "    return filter_food_cal(spice,non_recom_list,user_feat,user_id),loc \n",
    "    \n",
    "def filter_food_cal(sspice,non_recom_list,user_feat,user_id):\n",
    "    index = np.where(user_feat['user_guid']==user_id)[0][0]\n",
    "    sspice = sspice[sspice['NonVeg']==user_feat.loc[index,'NonVeg']]\n",
    "    #print spice\n",
    "    s_spice =  sspice.sort_values('count',ascending=[0])\n",
    "    s_index = s_spice.index[~s_spice.index.isin(non_recom_list)]\n",
    "    #print ' rec ',non_recom_list\n",
    "    new_spices = s_spice[s_spice.index.isin(s_index)]\n",
    "    #print new_spices\n",
    "    new_spices = new_spices[new_spices['calorie']<user_feat.loc[index,'Calorie']]\n",
    "    return new_spices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation(user_group,user_id,non_recom_list,user_feat,spice_feat):\n",
    "    new_spices,loc = filter_food_loc(user_group,user_id,non_recom_list,user_feat,spice_feat)\n",
    "    recommend = []\n",
    "    for i in range(min(3,len(new_spices))):\n",
    "        recommend.append(new_spices.index[i])\n",
    "\n",
    "    if(len(recommend)==0):\n",
    "        other_state_spice = spice_feat[spice_feat['Location'].isin(loc)==False]\n",
    "\n",
    "        other_state_spice = other_state_spice.sort('count',ascending= [0])\n",
    "        new_other_state = other_state_spice[~other_state_spice.index.isin(non_recom_list)]\n",
    "\n",
    "        for i in range(min(3,len(new_other_state))):\n",
    "            recommend.append(new_other_state.index[i])\n",
    "            \n",
    "    return recommend    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we have user_table which will give rating to a particular dish\n",
    "# content based recommeder system\n",
    "# we have 2 tables with us\n",
    "\n",
    "#one is food - spices table and another is food-user rating table\n",
    "#we will use tf-idf approach\n",
    "#matrix of spice will contain only of 1 and 0's so need to normalize it\n",
    "\n",
    "#normalization along the row\n",
    "def spice_norm(spice):\n",
    "    \n",
    "    num_attr = np.sum(spice,axis=1)\n",
    "    doc_vec = []\n",
    "    for i in range(num_attr.shape[0]):\n",
    "        if(num_attr[i] != 0): \n",
    "            doc_vec.append(np.sqrt(spice[i,:]*1.0/num_attr[i]))\n",
    "        else:\n",
    "            doc_vec.append(spice[i,:])\n",
    "    return np.array(doc_vec)      \n",
    "    \n",
    "    \n",
    "    \n",
    "def attr_norm(spice):\n",
    "    \n",
    "    num_attr = np.sum(spice,axis=0)\n",
    "    \n",
    "    doc_vec = []\n",
    "    for i in range(num_attr.shape[0]):\n",
    "        if(num_attr[i] != 0):\n",
    "            doc_vec.append(spice[:,i]*1.0 / num_attr[i])\n",
    "        else:\n",
    "            doc_vec.append(spice[:,i])\n",
    "    return np.array(doc_vec)\n",
    "\n",
    "def user_v(spice_mat,user):\n",
    "    user_vec = []\n",
    "    \n",
    "    \n",
    "    #print user[:,0]\n",
    "    #print spice_mat[:,0]\n",
    "    \n",
    "    for i in range(user.shape[1]):\n",
    "        user_vec.append([np.dot(user[:,i],spice_mat[:,j]) for j in range(spice_mat.shape[1])])\n",
    "    \n",
    "    print (user_vec)\n",
    "    return np.array(user_vec)\n",
    "    \n",
    "def weight_predict(spice_mat,user):\n",
    "        \n",
    "    user_vec = user_v(spice_mat,user)\n",
    "    \n",
    "    preds = []\n",
    "    #print spice_mat\n",
    "    for i in range(spice_mat.shape[0]):\n",
    "        preds.append([np.dot(spice_mat[i,:],user_vec[j,:]) for j in range(user_vec.shape[0])])\n",
    "\n",
    "    return np.array(preds)\n",
    "    \n",
    "    \n",
    "def idf_weight_pred(user,spice):\n",
    "    spice_mat = spice_norm(spice)\n",
    "    attr_wght = attr_norm(spice)\n",
    "    #print attr_wght\n",
    "    weighted_spice = []\n",
    "    \n",
    "    for i in range(spice_mat.shape[0]):\n",
    "        weighted_spice.append([np.dot(spice_mat[i,:],attr_wght[:,j]) for j in range(attr_wght.shape[0])])\n",
    "        \n",
    "    preds  = weight_predict(np.array(weighted_spice),user)     \n",
    "    \n",
    "    return np.array(preds)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_reco(user_rating,spice):\n",
    "    preds = idf_weight_pred(np.array(user_rating),spice)\n",
    "    outputdf = pd.DataFrame(data = preds,index = user_rating.index ,columns = user_rating.columns)\n",
    "    return outputdf  \n",
    "\n",
    "def recommendation_content(user_id,spice_feat,user_rating,non_recom_list,user_feat,outputdf):\n",
    "    #spice_feat = np.array(spice_feat.iloc[:,0:4])\n",
    "    #outputdf = content_based_reco(user_rating,spice_feat)\n",
    "    \n",
    "    spice = filter_food_cal(spice_feat,non_recom_list,user_feat,user_id)\n",
    "    #print s_index\n",
    "    spice.index = spice['food_id']\n",
    "    output = outputdf[outputdf.index.isin(spice.index)]\n",
    "    #print user_df.columns\n",
    "    newoutput = output[user_id].sort_values(ascending = False)\n",
    "    #print newoutput\n",
    "    food_to_recommend = list(newoutput[0:3].index)\n",
    "\n",
    "    return  food_to_recommend\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_list(row):\n",
    "    x = str(row['last_5_days_recommend'])\n",
    "    y = str(row['last_5_days_bought'])\n",
    "    if isinstance(x,basestring):\n",
    "        x = ast.literal_eval(x)\n",
    "    if isinstance(y,basestring):\n",
    "        y = ast.literal_eval(y)    \n",
    "        \n",
    "    l1 =  list(itertools.chain.from_iterable(x))\n",
    "    l2 =  list(itertools.chain.from_iterable(y)) \n",
    "    #print l1+l2\n",
    "    return l1+l2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for next day\n",
    "#update the user_feat table for not recommenddation\n",
    "def change_last_recommend(x,y):\n",
    "    #print (row['last 5 days recommend'])\n",
    "    new_recommend = []\n",
    "    #print type(x) ,y,count \n",
    "    if isinstance(x,basestring):\n",
    "        x = ast.literal_eval(x)\n",
    "    if isinstance(y,basestring):\n",
    "        y = ast.literal_eval(y)    \n",
    "    for i in range(4):\n",
    "        new_recommend.append(x[i+1])\n",
    "    new_recommend.append(y)\n",
    "    #print new_recommend\n",
    "    return str(new_recommend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "global count\n",
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_items(user_id,non_recom_list,user,user_feat,spice_feat,user_rating,output_df):\n",
    "    #print type(non_recom_list)\n",
    "    l1 = recommendation(user,user_id,non_recom_list,user_feat,spice_feat)\n",
    "    print 'something1'\n",
    "    l2 = recommendation_content(user_id,spice_feat,user_rating,non_recom_list,user_feat,output_df)\n",
    "    \n",
    "    return str(l1+l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_type(x):\n",
    "    if isinstance(x,basestring):\n",
    "        x = ast.literal_eval(x)\n",
    "    return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_day_recommendation(user_feat,new_user_feat,spice_feat,user_rating):\n",
    "    new_user_feat['last_5_days_recommend'] = new_user_feat.apply(lambda x: change_last_recommend(x['last_5_days_recommend'], x['recommends']), axis=1)\n",
    "    new_user_feat['last_5_days_bought'] = new_user_feat.apply(lambda x: change_last_recommend(x['last_5_days_bought'], x['bought']), axis=1)\n",
    "    new_user_feat['not_recommended'] = new_user_feat.apply(convert_list,axis=1)\n",
    "    print new_user_feat['last_5_days_recommend'][0]\n",
    "    print new_user_feat['last_5_days_bought'][0] \n",
    "    print new_user_feat['not_recommended'][0]\n",
    "    user_group ,user_feat = clustering_based(user_feat)\n",
    "    spice = np.array(spice_feat.iloc[: ,0:4])\n",
    "    outputdf  = content_based_reco(user_rating, spice)\n",
    "    new_user_feat['not_recommended'] = new_user_feat.apply(lambda x:change_type(x['not_recommended']),axis=1)\n",
    "    #new_user_feat['not_recommended'].to_csv('not_recommended.csv',encoding='utf-8',index = False)\n",
    "    #print new_user_feat\n",
    "    new_user_feat['recommends'] = new_user_feat.apply(lambda x:recommend_items(x['user_guid'],x['not_recommended'],user_group,user_feat,spice_feat,user_rating,outputdf),axis=1)\n",
    "    print new_user_feat\n",
    "    return new_user_feat\n",
    "    \n",
    "def main_recommendation(user_feat,spice_feat,user_rating):\n",
    "    new_user_feat = pd.read_csv('new_user_feat.csv')\n",
    "    next_day = input('type 0 for recommending items or 1 for next_day recommendation') \n",
    "    if next_day == 1:\n",
    "        new_user_feat = next_day_recommendation(user_feat,new_user_feat,spice_feat,user_rating)\n",
    "        new_user_feat.to_csv('new_user_feat.csv',encoding='utf-8',index = False)       \n",
    "    else:\n",
    "        user_id = input('enter the user_id')\n",
    "        index = np.where(new_user_feat['user_guid']==user_id)[0]\n",
    "        print new_user_feat.loc[index[0],'recommends']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type 0 for recommending items or 1 for next_day recommendation559\n",
      "enter the user_id559\n",
      "[60074, 60089, 60051, 60077, 60051, 60087]\n"
     ]
    }
   ],
   "source": [
    "main_recommendation(user_feat,spice_feat,user_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
